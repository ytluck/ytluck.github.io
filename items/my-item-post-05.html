<!DOCTYPE html>
<html lang="zh_cn">
<head>
        <meta charset="utf-8" />
        <title>使用Scrapy进行爬取数据</title>
        <link rel="stylesheet" href="/theme/css/main.css" />

        <!--[if IE]>
            <script src="https://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">ytluck—For you </a></h1>
                <nav><ul>
                    <li><a href="http://ytluck.github.io/">Home</a></li>
                    <li><a href="/About me.html">About Me</a></li>
                    <li><a href="/big-data/index.html">Big Data</a></li>
                    <li><a href="/data-mining/index.html">Data Mining</a></li>
                    <li class="active"><a href="/items/index.html">Items</a></li>
                    <li><a href="/os/index.html">OS</a></li>
                    <li><a href="/program/index.html">Program</a></li>
                </ul></nav>
        </header><!-- /#banner -->
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="/items/my-item-post-05.html" rel="bookmark"
           title="Permalink to 使用Scrapy进行爬取数据">使用Scrapy进行爬取数据</a></h1>
    </header>

    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2016-09-14T13:27:00+08:00">
                Published: 2016-09-14 13:27:00
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/ytwan.html">ytwan</a>
        </address>
<p>In <a href="/items/index.html">Items</a>.</p>
<p>tags: <a href="/tag/python.html">Python</a> </p>
</footer><!-- /.post-info -->      <h2>1.创建爬虫weather</h2>
<div class="highlight"><pre><span></span>scrapy  startproject   weather
这条命令会产生如下的文件夹以及文件
weather.
├── scrapy.cfg
└── weather
    ├── __init__.py
    ├── items.py
    ├── pipelines.py
    ├── settings.py
    └── spiders
        └── __init__.py
weather/文件下有如下：
  scrapy.cfg    : 项目配置文件
  weather/      : 项目python模块, 之后您将在此加入代码
    items.py    : 项目items文件
    pipelines.py: 项目管道文件
    settings.py : 项目配置文件
    spiders/    : 放置spider的目录
项目根目录==在项目的scrapy.cfg文件同级目录
</pre></div>


<h2>2、编写必要的组件</h2>
<div class="highlight"><pre><span></span>明确目标（Items）：明确你想要抓取的目标
制作爬虫（Spider）：制作爬虫开始爬取网页
存储内容（Pipeline）：设计管道存储爬取内容

  &lt;1&gt;. item 可以用 scrapy.item.Item 类来创建，并且用 scrapy.item.Field 对象来定义属性（可以理解成类似于 ORM 的映射关系）。
    接下来，我们开始来构建 item 模型（model）。
    首先，我们想要的内容有：
        名称（name）
        链接（url）
        描述（description）
    修改 weather 目录下的 items.py 文件，在原本的 class 后面添加我们自己的 clas
  &lt;2&gt;.制作爬虫（Spider）
    制作爬虫，总体分两步：先爬再取。
    也就是说，首先你要获取整个网页的所有内容，然后再取出其中对你有用的部分。
        爬
          Spider 是用户自己编写的类，用来从一个域（或域组）中抓取信息。 他们定义了用于下载的 URL 列表、跟踪链接的方案、解析网页内容的方式，以此来提取 items。 要建立一个 Spider，你必须用 scrapy.spider.BaseSpider 创建一个子类，并确定三个强制的属性：
            name：爬虫的识别名称，必须是唯一的，在不同的爬虫中你必须定义不同的名字。
            start_urls：爬取的 URL 列表。爬虫从这里开始抓取数据，所以，第一次下载的数据将会从这些 urls 开始。其他子 URL 将会从这些起始 URL 中继承性生成。
            parse()：解析的方法，调用的时候传入从每一个 URL 传回的 Response 对象作为唯一参数，负责解析并匹配抓取的数据(解析为 item)，跟踪更多的 URL。
        取
          爬取整个网页完毕，接下来的就是的取过程了。光存储一整个网页还是不够用的。在基础的爬虫里，这一步可以用正则表达式来抓。
          在 Scrapy 里，使用一种叫做 XPath selectors 的机制，它基于 XPath 表达式。 
  &lt;3&gt;.存储内容（Pipeline）
    保存信息的最简单的方法是通过 Feed exports，主要有四种：JSON，JSON lines，CSV，XML。 我们将结果用最常用的 JSON 导出
    写好ITEM_PIPELINES后，还有很重要的一步，就是把 ITEM_PIPELINES 添加到设置文件 settings.py 中。
</pre></div>


<h2>3、运行爬虫</h2>
<div class="highlight"><pre><span></span>到项目根目录, 然后运行命令
cd  weather  
运行命令
scrapy  crawl
</pre></div>


<h2>4.示例</h2>
<h3>items.py</h3>
<div class="highlight"><pre><span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="kn">import</span> <span class="nn">scrapy</span>
<span class="k">class</span> <span class="nc">WeatherItem</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Item</span><span class="p">):</span>
<span class="n">city</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
<span class="n">date</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
<span class="n">dayDesc</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
<span class="n">dayTemp</span> <span class="o">=</span> <span class="n">scrapy</span><span class="o">.</span><span class="n">Field</span><span class="p">()</span>
</pre></div>


<h3>pipelines.py</h3>
<div class="highlight"><pre><span></span><span class="c c-Singleline"># -*- coding: utf-8 -*-</span>
<span class="k">class</span> <span class="n">WeatherPipeline</span>(<span class="n">object</span>):
<span class="n">def</span> <span class="n">__init__</span>(<span class="k">self</span>):
    <span class="nb">pass</span>

<span class="n">def</span> <span class="n">process_item</span>(<span class="k">self</span>, <span class="n">item</span>, <span class="n">spider</span>):
    <span class="n">with</span> <span class="nb">open</span>(<span class="s">&#39;wea.txt&#39;</span>, <span class="s">&#39;w+&#39;</span>) <span class="k">as</span> <span class="n">file:</span>
        <span class="n">city</span> = <span class="n">item</span>[<span class="s">&#39;city&#39;</span>][<span class="mi">0</span>].<span class="n">encode</span>(<span class="s">&#39;utf-8&#39;</span>)
        <span class="n">file</span>.<span class="nb">write</span>(<span class="s">&#39;city:&#39;</span> + <span class="n">str</span>(<span class="n">city</span>) + <span class="s">&#39;\n\n&#39;</span>)

        <span class="n">date</span> = <span class="n">item</span>[<span class="s">&#39;date&#39;</span>]

        <span class="n">desc</span> = <span class="n">item</span>[<span class="s">&#39;dayDesc&#39;</span>]
        <span class="n">dayDesc</span> = <span class="n">desc</span>[<span class="mi">1</span>::<span class="mi">2</span>]
        <span class="n">nightDesc</span> = <span class="n">desc</span>[<span class="mi">0</span>::<span class="mi">2</span>]



        <span class="n">weaitem</span> = <span class="nb">zip</span>(<span class="n">date</span>, <span class="n">dayDesc</span>, <span class="n">nightDesc</span>)

        <span class="k">for</span> <span class="n">i</span> <span class="n">in</span> <span class="n">range</span>(<span class="n">len</span>(<span class="n">weaitem</span>)):
            <span class="n">item</span> = <span class="n">weaitem</span>[<span class="n">i</span>]
            <span class="n">d</span> = <span class="n">item</span>[<span class="mi">0</span>]
            <span class="n">dd</span> = <span class="n">item</span>[<span class="mi">1</span>]
            <span class="n">nd</span> = <span class="n">item</span>[<span class="mi">2</span>]
            <span class="n">txt</span> = <span class="s">&#39;date:{0}\t\tday:{1}({2})\t\t&#39;</span>.<span class="n">format</span>(
                <span class="n">d</span>,
                <span class="n">dd</span>.<span class="n">encode</span>(<span class="s">&#39;utf-8&#39;</span>),
                <span class="n">nd</span>.<span class="n">encode</span>(<span class="s">&#39;utf-8&#39;</span>)
            )
            <span class="n">file</span>.<span class="nb">write</span>(<span class="n">txt</span>)
    <span class="k">return</span> <span class="n">item</span>
</pre></div>


<h3>settings.py</h3>
<div class="highlight"><pre><span></span># -*- coding: utf-8 -*-
BOT_NAME = &#39;Googlebot&#39;
SPIDER_MODULES = [&#39;weather.spiders&#39;]
NEWSPIDER_MODULE = &#39;weather.spiders&#39;
USER_AGENT = &#39;User-Agent: Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.106 Safari/537.36&#39;
DEFAULT_REQUEST_HEADERS = {
    &#39;Referer&#39;: &#39;http://www.weibo.com&#39;
}
ITEM_PIPELINES = {
    &#39;weather.pipelines.WeatherPipeline&#39;: 1
}
DOWNLOAD_DELAY = 0.5
</pre></div>


<h3>spider</h3>
<div class="highlight"><pre><span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="kn">import</span> <span class="nn">scrapy</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">from</span> <span class="nn">weather.items</span> <span class="kn">import</span> <span class="n">WeatherItem</span>

<span class="k">class</span> <span class="nc">WeatherSpider</span><span class="p">(</span><span class="n">scrapy</span><span class="o">.</span><span class="n">Spider</span><span class="p">):</span>
<span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;myweather&quot;</span>
<span class="n">allowed_domains</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;sina.com.cn&quot;</span><span class="p">]</span>
<span class="n">start_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;http://weather.sina.com.cn&#39;</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">response</span><span class="p">):</span>
    <span class="n">html_doc</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">body</span>
    <span class="c1">#html_doc = html_doc.decode(&#39;utf-8&#39;)</span>
    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">html_doc</span><span class="p">)</span>
    <span class="n">itemTemp</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">itemTemp</span><span class="p">[</span><span class="s1">&#39;city&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s1">&#39;slider_ct_name&#39;</span><span class="p">)</span>
    <span class="n">tenDay</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s1">&#39;blk_fc_c0_scroll&#39;</span><span class="p">)</span>
    <span class="n">itemTemp</span><span class="p">[</span><span class="s1">&#39;date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tenDay</span><span class="o">.</span><span class="n">findAll</span><span class="p">(</span><span class="s2">&quot;p&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;class&quot;</span><span class="p">:</span> <span class="s1">&#39;wt_fc_c0_i_date&#39;</span><span class="p">})</span>
    <span class="n">itemTemp</span><span class="p">[</span><span class="s1">&#39;dayDesc&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tenDay</span><span class="o">.</span><span class="n">findAll</span><span class="p">(</span><span class="s2">&quot;img&quot;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;class&quot;</span><span class="p">:</span> <span class="s1">&#39;icons0_wt&#39;</span><span class="p">})</span>
    <span class="n">itemTemp</span><span class="p">[</span><span class="s1">&#39;dayTemp&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">tenDay</span><span class="o">.</span><span class="n">findAll</span><span class="p">(</span><span class="s1">&#39;p&#39;</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;class&quot;</span><span class="p">:</span> <span class="s1">&#39;wt_fc_c0_i_temp&#39;</span><span class="p">})</span>
    <span class="n">item</span> <span class="o">=</span> <span class="n">WeatherItem</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">att</span> <span class="ow">in</span> <span class="n">itemTemp</span><span class="p">:</span>
        <span class="n">item</span><span class="p">[</span><span class="n">att</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">att</span> <span class="o">==</span> <span class="s1">&#39;city&#39;</span><span class="p">:</span>
            <span class="n">item</span><span class="p">[</span><span class="n">att</span><span class="p">]</span> <span class="o">=</span> <span class="n">itemTemp</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">att</span><span class="p">)</span><span class="o">.</span><span class="n">text</span>
            <span class="k">continue</span>
        <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="n">itemTemp</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">att</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">att</span> <span class="o">==</span> <span class="s1">&#39;dayDesc&#39;</span><span class="p">:</span>
                <span class="n">item</span><span class="p">[</span><span class="n">att</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">obj</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">item</span><span class="p">[</span><span class="n">att</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">obj</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">item</span>
</pre></div>


<h2>启动爬虫</h2>
<div class="highlight"><pre><span></span>scrapy crawl  weather
</pre></div>


<h2>4.注意事项</h2>
<div class="highlight"><pre><span></span>明确目标：
    对目标网站的规模和结构进行了解
            对网站进行背景调查--
                估算网站大小，识别网站使用的技术。
    对爬取的数据进行了解--
            URL格式&lt;路径规划--确定解析规则&gt;
            数据格式&lt;确定提取格式&gt;
            其他&lt;Encoding等&gt;
爬虫设定
    其中时间设定很重要，因为很多网站都对其进行了设定
    过快则可能被禁，甚至IP遭到封杀。调试的时候注意
阶段：
    多个网页
    动态网页爬取--JavaScript
    表单交互--和网页进行交互--登陆网站
    验证码处理
    并发下载--多线程和多进程网页下载
    缓存
</pre></div>
    </div><!-- /.entry-content -->

  </article>
</section>
        <section id="extras" class="body">
                <div class="blogroll">
                        <h2>blogroll</h2>
                        <ul>
                            <li><a href="http://getpelican.com/">Pelican</a></li>
                            <li><a href="http://python.org/">Python.org</a></li>
                            <li><a href="https://github.com/ytluck">yt</a></li>
                        </ul>
                </div><!-- /.blogroll -->
                <div class="social">
                        <h2>social</h2>
                        <ul>

                            <li><a href="http://pelican-zh.readthedocs.org/en/latest/zh-cn/settings/">ye</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>, which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="http://coding.smashingmagazine.com/2009/08/04/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-76643035-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = 'https://ssl.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>
</body>
</html>