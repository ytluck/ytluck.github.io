<!DOCTYPE html>
<html lang="zh_cn">
<head>
        <meta charset="utf-8" />
        <title>ytluck—For you - Flink</title>
        <link rel="stylesheet" href="/theme/css/main.css" />

        <!--[if IE]>
            <script src="https://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">ytluck—For you </a></h1>
                <nav><ul>
                    <li><a href="http://ytluck.github.io/">Home</a></li>
                    <li><a href="/About me.html">About Me</a></li>
                    <li><a href="/big-data/index.html">Big Data</a></li>
                    <li><a href="/data-mining/index.html">Data Mining</a></li>
                    <li><a href="/items/index.html">Items</a></li>
                    <li><a href="/os/index.html">OS</a></li>
                    <li><a href="/program/index.html">Program</a></li>
                </ul></nav>
        </header><!-- /#banner -->

            <aside id="featured" class="body">
                <article>
                    <h1 class="entry-title"><a href="/big-data/my-bigdata-post-52.html">Flink和Kafka以及Kafka生产者</a></h1>
<footer class="post-info">
        <abbr class="published" title="2019-07-08T22:10:00+08:00">
                Published: 2019-07-08 22:10:00
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/ytwan.html">ytwan</a>
        </address>
<p>In <a href="/big-data/index.html">Big Data</a>.</p>
<p>tags: <a href="/tag/flink.html">Flink</a> </p>
</footer><!-- /.post-info --><h3>1.Kafka版本说明：</h3>
<div class="highlight"><pre><span></span>01.Producer： Kafka 0.8.2, Producer被重新设计，
   新版生产者：
      org.apache.kafka.clients
       org.apache.kafka.clients.producer.KafkaProducer;
   旧版的生产者：
      旧版本（0.8Scala版本）  kafka.javaapi.producer.Producer;
02.Consumer
   Kafka 0.9 则重新设计了Consumer接口。它不再区分high-level
   consumer API和low-level consumer API，而是提供了一个统一的consumer API
   Kafka 消费者总共有 3 种 API，新版 API、旧版高级 API、旧版低级 API，
     新版 API 是在 kafka 0.9 版本后增加的，推荐使用新版 API，但由于旧版低级 API 可以对消息进行更加灵活的控制
  新版：
    Consumer    org.apache.kafka.clients.consumer.KafkaConsumer;
  旧版Consumer
    High Level Consumer API 入口类： ConsumerConnector  kafka.javaapi.consumer.ConsumerConnector;    
    Lower Level Consumer API入口类： SimpleConsumer     kafka.javaapi.consumer.SimpleConsumer; 
  新版 Consumer
 03.Connect -Kafka Connect
   Kafka Connect是到0.9版本才提供的并极大的简化了其他系统与Kafka的集成
</pre></div>


<h3>2.Kafka配置信息</h3>
<div class="highlight"><pre><span></span>Kafka 提供内置客户端以及二进制连接协议
1.使用场景评估：
     01.每个消息都很重要，是否允许丢失一小部分消息
     02.出现重复消息是否可以接受
     03.是否有严格的延迟和吞吐量要求
2.依据场景进行配置
    类型，时间，大小，次数
  配置的评估
   client.id
     识别消息来源
   acks 参数指定了必须要有多少个区分副本收到消息，生产者才会认为消息写入成功
    消息丢失的可能性：
     acks=0  acks=1  acks=all
   buffer.memory
     设置生产者内存缓冲区的大小
   compression.type
      snappy gzip
   retries
     决定了生产者重发消息的次数 默认间隔时间 100ms
     retry.backoff.ms 参数来改变时间间隔
   batch.size
     同一个批次可以使用的内存大小，按照字节数计算，而不是消息个数
   linger.ms
     发送之前等待更多消息加入批次的时间
     KafkaProducer 会根据批次填满  batch.size 或者批次等待时间时间达到上限 linger.ms 将批次发送出去

   时间：
     timeout.ms
     request.timeout.ms
     matadata.fetch.timeout.ms
    阻塞时间
     max.block.ms
    大小：
     max.request.size
     receive.buffer.bytes
     send.buffer.bytes
    顺序保证：
       max.in.flight.requests.per.connection
</pre></div>


<h3>3.开发过程：</h3>
<div class="highlight"><pre><span></span>   A: 创建生产者，生产者要把键值对象序列化成字节数组-三个必选属性
       bootstrap.servers   key.serializer  value.serializer
   B: 创建一个 ProducerRecord  对象，该对象包含目标主题和要发送的内容，还可以指定键或者分区
       两种线程： 单线程和多线程
       三种发送消息的方式：
         同步发送    send() 发送消息，返回Future对象
         异步发送    send() 方法，并指定一个回调函数
         发送并忘记： fire and forget          
   C：消息成功写入Kafka会返回一个 RecordMetadata  对象，写入失败则会返回一个错误。
      收到错误还会尝试，几次失败后，就返回错误信息。
   说明： key.serializer 实现了 org.apache.kafka.common.serialization.Serializer接口的类
      Kafka默认提供三种 StringSerializer IntegerSerializer  ByteSerializer 
  01.pom.xml依赖
     开发版本
         <span class="nt">&lt;groupId&gt;</span>org.apache.kafka<span class="nt">&lt;/groupId&gt;</span>
         <span class="nt">&lt;artifactId&gt;</span>kafka-clients<span class="nt">&lt;/artifactId&gt;</span>
         <span class="nt">&lt;version&gt;</span>0.8.2.2<span class="nt">&lt;/version&gt;</span>
  示例代码：
    // 步骤1 新建一个 Properties对象-并配置三个必选属性
     Properties kafkaProps = new Properties();
      kafkaProps.put(&quot;bootstrap.servers&quot;, &quot;broker1:9092,broker2:9092&quot;);
      kafkaProps.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
      kafkaProps.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;);
   // 步骤2 创建新的生产者对象 KafkaProducer ，并把设置好的 Properties 对象传给它
     Producer<span class="nt">&lt;String</span><span class="err">,</span> <span class="err">String</span><span class="nt">&gt;</span>  producer=  new KafkaProducer<span class="nt">&lt;String</span><span class="err">,String</span><span class="nt">&gt;</span>(kafkaProps);
   // 步骤3 开始发送消息，生产者将 ProducerRecord 对象作为参数发送，使用send() 方法发送
     ProducerRecord<span class="nt">&lt;String</span><span class="err">,</span> <span class="err">String</span><span class="nt">&gt;</span> record = new ProducerRecord<span class="nt">&lt;String</span><span class="err">,</span> <span class="err">String</span><span class="nt">&gt;</span>(&quot;&quot;, &quot;&quot;, &quot;&quot;);
     Future<span class="nt">&lt;RecordMetadata&gt;</span> kafkaFuture = producer.send(record);
  // 同步发送消息调用get 方法等待Kafka相应，运行正常则返回一个 RecordMetadata 对象
   // 一般会发生两类错误，一类是可重试错误，一类无法通过重试解决，比如消息太大等
   try {   kafkaFuture.get();
    } catch (Exception e) {
       e.printStackTrace;
    }
    // 异步发送--回调支持
    producer.send(record, new DemoProducerCallback());
    // private class  DemoProducerCallback implements Callback{ onCpmpletion(RecordMetadata )}
扩展：
  Producer端，需要自己创造多线程并发环境才能提高客户端的出口吞吐量
</pre></div>


<h3>Flink向kafka发送数据</h3>
<div class="highlight"><pre><span></span>Kafka sink connector（FlinkKafkaProducer）
  Flink里面支持Kafka 0.8、0.9、0.10、0.11.
pom.xml依赖
 <span class="nt">&lt;dependency&gt;</span>
   <span class="nt">&lt;groupId&gt;</span>org.apache.flink<span class="nt">&lt;/groupId&gt;</span>
   <span class="nt">&lt;artifactId&gt;</span>flink-connector-kafka-0.11_2.11<span class="nt">&lt;/artifactId&gt;</span>
   <span class="nt">&lt;version&gt;</span><span class="cp">${</span><span class="n">flink</span><span class="o">.</span><span class="n">version</span><span class="cp">}</span><span class="nt">&lt;/version&gt;</span>
 <span class="nt">&lt;/dependency&gt;</span>
执行：
 // 添加数据源addSource
  DataStreamSource<span class="nt">&lt;String&gt;</span> student = env.addSource(new FlinkKafkaConsumer011<span class="err">&lt;</span>&gt;(
            READ_TOPIC,   //这个 kafka topic 需要和上面的工具类的 topic 一致
            new SimpleStringSchema(),
            props)).setParallelism(1);

  // 创建kafka数据流
 //  Producer 传了三个参数：brokerList、topicId、serializationSchema（序列化）
 student.addSink(new FlinkKafkaProducer011<span class="err">&lt;</span>&gt;(
            &quot;localhost:9092&quot;,
            &quot;student-write&quot;,
            new SimpleStringSchema()
    )).name(&quot;flink-connectors-kafka&quot;)
            .setParallelism(5);
Flink Kafka Consumer 的运行机制
</pre></div>


<h3>JSON作为消息</h3>
<div class="highlight"><pre><span></span><span class="nt">JSON</span> <span class="nt">-</span> <span class="o">(</span><span class="nt">JavaScript</span> <span class="nt">Object</span> <span class="nt">Notation</span><span class="o">)</span>
<span class="err">数据类型：</span>      
    <span class="nt">JSON</span><span class="err">只定义了两种数据结构，即数组</span><span class="cp">[]</span><span class="err">和对象</span><span class="p">{}</span><span class="err">。对象是一组键值对</span>
    <span class="nt">JSON</span><span class="err">的键</span><span class="o">:</span> <span class="nt">String</span>
    <span class="nt">JSON</span><span class="err">的值</span><span class="o">:</span> <span class="nt">1</span><span class="o">.</span><span class="err">数字（整数或浮点数）</span>    <span class="nt">2</span><span class="o">.</span><span class="err">字符串（在双引号中）</span>
         <span class="nt">3</span><span class="o">.</span><span class="err">逻辑值（</span><span class="nt">true</span> <span class="err">或</span> <span class="nt">false</span><span class="err">）</span> <span class="nt">4</span><span class="nc">.null</span>
         <span class="nt">5</span><span class="o">.</span><span class="err">数组（在方括号中）</span>      <span class="nt">6</span><span class="o">.</span><span class="err">对象（在花括号中）</span>
    <span class="err">符号：</span> <span class="err">花括弧，方括弧，冒号和逗号</span>
<span class="nt">JSON</span><span class="err">解析</span>
<span class="nt">fasterjson</span> <span class="err">是一个</span><span class="nt">JSON</span><span class="err">解析器。它直接解析</span><span class="nt">JSON</span><span class="err">文本，调用注册的事件函数，快速访问</span><span class="nt">JSON</span><span class="err">中感兴趣的内容</span>
<span class="nt">Fastjson</span> <span class="nt">API</span><span class="err">入口类是</span><span class="nt">com</span><span class="nc">.alibaba.fastjson.JSON</span>
 <span class="nt">eg</span><span class="o">:</span>  <span class="nt">JSONObject</span> <span class="nt">jsObj</span> <span class="o">=</span> <span class="nt">new</span> <span class="nt">JSONObject</span><span class="o">();</span>
<span class="err">类型：</span>
   <span class="nt">JSONObject</span>  <span class="nt">JSONArray</span>   <span class="nt">Object</span>  <span class="nt">List</span>  <span class="nt">String</span> 
<span class="err">方法：</span>
    <span class="nt">parse</span> <span class="nt">parseObject</span> <span class="nt">parseArray</span>
    <span class="nt">toJSON</span>  <span class="nt">toJSONString</span>
<span class="err">注意事项：</span>
 <span class="nt">JSONObject</span> <span class="err">是一个</span><span class="nt">json</span>
<span class="nt">JSONArray</span><span class="nc">.toJSONString</span><span class="o">()</span> <span class="err">之后不是一个</span><span class="nt">json</span><span class="err">，而是</span><span class="nt">json</span><span class="err">中的一个数组</span>
<span class="nt">JSON</span><span class="nc">.toJSONString</span><span class="o">()</span> <span class="err">不可多次使用，（最好转义一次）</span> <span class="err">因为每次调用</span><span class="nt">JSON</span><span class="nc">.toJSONString</span><span class="err">的时候，</span>
     <span class="err">在</span><span class="nt">key</span><span class="err">和</span><span class="nt">value</span><span class="err">前后都会加上&quot;的转义符\&#39;。多次使用</span><span class="nt">toJSONString</span><span class="err">了之后</span><span class="o">,</span><span class="nt">json</span><span class="err">的每个</span><span class="nt">key</span><span class="err">和</span><span class="nt">value</span><span class="err">有多个转义符</span>
</pre></div>


<h3>参考：</h3>
<div class="highlight"><pre><span></span>Kafka权威指南
Flink 写入数据到 Kafka https://www.jianshu.com/p/c94317de9692
</pre></div>                </article>
            </aside><!-- /#featured -->
                <section id="content" class="body">
                    <h1>Other articles</h1>
                    <hr />
                    <ol id="posts-list" class="hfeed">

            <li><article class="hentry">
                <header>
                    <h1><a href="/big-data/my-bigdata-post-51.html" rel="bookmark"
                           title="Permalink to Flink数据类型和Tuple">Flink数据类型和Tuple</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2019-07-08T21:10:00+08:00">
                Published: 2019-07-08 21:10:00
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/ytwan.html">ytwan</a>
        </address>
<p>In <a href="/big-data/index.html">Big Data</a>.</p>
<p>tags: <a href="/tag/flink.html">Flink</a> </p>
</footer><!-- /.post-info -->                <p>类型推断 Type_Information DataStreaming Table</p>
                <a class="readmore" href="/big-data/my-bigdata-post-51.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>
                </ol><!-- /#posts-list -->
                </section><!-- /#content -->
        <section id="extras" class="body">
                <div class="blogroll">
                        <h2>blogroll</h2>
                        <ul>
                            <li><a href="http://getpelican.com/">Pelican</a></li>
                            <li><a href="http://python.org/">Python.org</a></li>
                            <li><a href="https://github.com/ytluck">yt</a></li>
                        </ul>
                </div><!-- /.blogroll -->
                <div class="social">
                        <h2>social</h2>
                        <ul>

                            <li><a href="http://pelican-zh.readthedocs.org/en/latest/zh-cn/settings/">ye</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>, which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="http://coding.smashingmagazine.com/2009/08/04/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-76643035-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = 'https://ssl.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>
</body>
</html>