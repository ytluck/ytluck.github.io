<!DOCTYPE html>
<html lang="zh_cn">
<head>
        <meta charset="utf-8" />
        <title>Spark不同版本的接入点</title>
        <link rel="stylesheet" href="/theme/css/main.css" />

        <!--[if IE]>
            <script src="https://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">ytluck—For you </a></h1>
                <nav><ul>
                    <li><a href="http://ytluck.github.io/">Home</a></li>
                    <li><a href="/About me.html">About Me</a></li>
                    <li class="active"><a href="/big-data/index.html">Big Data</a></li>
                    <li><a href="/data-mining/index.html">Data Mining</a></li>
                    <li><a href="/items/index.html">Items</a></li>
                    <li><a href="/os/index.html">OS</a></li>
                    <li><a href="/program/index.html">Program</a></li>
                </ul></nav>
        </header><!-- /#banner -->
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="/big-data/my-bigdata-post-33.html" rel="bookmark"
           title="Permalink to Spark不同版本的接入点">Spark不同版本的接入点</a></h1>
    </header>

    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2018-07-24T19:59:00+08:00">
                Published: 2018-07-24 19:59:00
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/ytwan.html">ytwan</a>
        </address>
<p>In <a href="/big-data/index.html">Big Data</a>.</p>
<p>tags: <a href="/tag/things.html">things</a> </p>
</footer><!-- /.post-info -->      <div class="highlight"><pre><span></span>不同历史版本的接入点不同，而不同项目同时存在不同版本的使用的时候，
就要快速区分不同的API，以版本和基于的数据类型以及应用场景做区分
</pre></div>


<h3>1.6版本的Spark(Scala API)</h3>
<div class="highlight"><pre><span></span>1.接入点
离线 1 .：RDD作为API
          创建一个SparkConf对象来配置应用，
             基于这个SparkConf 创建一个SparkContext对象
             然后创建RDD
           //    val sc = new SparkContext(sparkConf)
          //          sc.textFile()、sc.sequenceFile()、sc.parallelize()  
离线2 ：DataSet和DataFrame的API
            1.6版本的接入点
                SQLContext(sc)
                HiveContext(sc)     
实时：基于DStream
      Spark Streaming -- 
         基于这个SparkConf 创建一个 StreamingContext 对象
         然后创建一个 DStream 
           //    ssc = new StreamingContext(sparkConf, Seconds(5)) 或者 new StreamingContext(sc, Seconds(1))
            ssc.socketTextStream、
机器学习
       the RDD-based APIs in the spark.mllib
       the  DataFrame-based API in the spark.ml
2.常见数据结构和常见操作
    常见数据结构  RDD、pair RDD、共享变量&lt;accumulators&gt;和广播变量
      基于RDD的  DStream
      以及 DataSet和DataFrame
    常见操作：
       三类操作
        transformation      转化操作
        action              行动操作
</pre></div>


<h3>2.2版本的Spark(Scala API)</h3>
<div class="highlight"><pre><span></span>离线1、
  val conf = new SparkConf().setAppName(appName).setMaster(master)
   new SparkContext(conf)

离线2、Spark SQL, DataFrames and Datasets
    2.0版本- 接入点
   在spark2.0中，引入SparkSession作为DataSet和DataFrame API的切入点，
    SparkSession封装了SparkConf、SparkContext和SQLContext。
    val spark =  SparkSession.builder()
         .appName(getProperties(&quot;mr.AppName&quot;))
         .config(&quot;spark.sql.warehouse.dir&quot;, warehouseLocation)
         .master(getProperties(&quot;mr.master&quot;))
         .enableHiveSupport()
         .getOrCreate()
实时1、Spark Streaming
          val conf = new SparkConf().setMaster(&quot;local[2]&quot;).setAppName(&quot;NetworkWordCount&quot;)
          val ssc = new StreamingContext(conf, Seconds(1))

实时2、 Structure Streaming
        01. 微批次处理(micro-batch processing)-
             支持流 DataFrame/Dataset 和静态数据集之间的 join
    //读取kafka的主题topic，并将数据注册为临时表 dy_test
    val  spark =   SparkSession
             .builder()
             .config(new SparkConf().setMaster(getProperties(&quot;mr.master&quot;)))
             .appName(getProperties(&quot;mr.appName&quot;))
             .getOrCreate()
    import spark.implicits._
    val df = spark
           .readStream
           .format(&quot;kafka&quot;)
           .option(&quot;kafka.bootstrap.servers&quot;, getProperties(&quot;kafka.brokers&quot;))
           .option(&quot;subscribe&quot;, topicName)
           .load()
机器学习
       the  DataFrame-based API in the spark.ml
图算法
   GraphX
</pre></div>


<h3>2.3版本的Spark(Scala API)</h3>
<div class="highlight"><pre><span></span>实时2、 Structure Streaming
            01. 微批次处理(micro-batch processing)
                    流和流的 Join 操作。支持内连接和外连接
            02.连续模式(continuous mode)-毫秒级低延迟(millisecond low-latency)模式
              流读取器连续拉取源数据并处理数据，而不是按指定的触发时间间隔读取一批数据。
              通过不断地查询源数据和处理数据，新的记录在到达时立即被处理，将等待时间缩短到毫秒，
              满足低延迟的应用程序的需求
                 支持的数据源： 
                 支持的操作：支持 map-like Dataset 操作，包括投影(projections)、selections以及其他 SQL 函数
Spark 作业可以和 Kubernetes 集群上的其他作业共享资源
</pre></div>
    </div><!-- /.entry-content -->

  </article>
</section>
        <section id="extras" class="body">
                <div class="blogroll">
                        <h2>blogroll</h2>
                        <ul>
                            <li><a href="http://getpelican.com/">Pelican</a></li>
                            <li><a href="http://python.org/">Python.org</a></li>
                            <li><a href="https://github.com/ytluck">yt</a></li>
                        </ul>
                </div><!-- /.blogroll -->
                <div class="social">
                        <h2>social</h2>
                        <ul>

                            <li><a href="http://pelican-zh.readthedocs.org/en/latest/zh-cn/settings/">ye</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>, which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="http://coding.smashingmagazine.com/2009/08/04/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-76643035-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = 'https://ssl.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>
</body>
</html>