<!DOCTYPE html>
<html lang="zh_cn">
<head>
        <meta charset="utf-8" />
        <title>Spark项目整个开发流程</title>
        <link rel="stylesheet" href="/theme/css/main.css" />

        <!--[if IE]>
            <script src="https://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">ytluck—For you </a></h1>
                <nav><ul>
                    <li><a href="http://ytluck.github.io/">Home</a></li>
                    <li><a href="/About me.html">About Me</a></li>
                    <li class="active"><a href="/big-data/index.html">Big Data</a></li>
                    <li><a href="/data-mining/index.html">Data Mining</a></li>
                    <li><a href="/items/index.html">Items</a></li>
                    <li><a href="/os/index.html">OS</a></li>
                    <li><a href="/program/index.html">Program</a></li>
                </ul></nav>
        </header><!-- /#banner -->
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="/big-data/my-bigdata-post-05.html" rel="bookmark"
           title="Permalink to Spark项目整个开发流程">Spark项目整个开发流程</a></h1>
    </header>

    <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2016-11-08T22:39:00+08:00">
                Published: 2016-11-08 22:39:00
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/ytwan.html">ytwan</a>
        </address>
<p>In <a href="/big-data/index.html">Big Data</a>.</p>
<p>tags: <a href="/tag/things.html">things</a> </p>
</footer><!-- /.post-info -->      <h2>0. 操作系统以及网络环境方面的设置</h2>
<div class="highlight"><pre><span></span>C:\WINDOWS\system32\drivers\etc\hosts
</pre></div>


<h2>1.安装语言环境和开发工具</h2>
<div class="highlight"><pre><span></span> &lt;1&gt;  安装JDK
      安装SDK
 &lt;2&gt; 安装开发集成工具 Intellij
     在Intellij中安装Scala插件
</pre></div>


<h2>2.配置环境</h2>
<div class="highlight"><pre><span></span>在开发环境中需要下载JDK以及SDK Scala，而在生产环境中，Spark运行依赖于SDK Scala，但是在我们的生产环境中预编译的二进制包中含有Scala运行环境，所以不需要额外的安装Scala，但是在我们的单机开发环境下，需要同时安装JDK以及SDK
</pre></div>


<h3>Spark本地环境开发调试</h3>
<div class="highlight"><pre><span></span>&lt;1&gt; 创建工程
&lt;2&gt;本地开发调试不需要任何已经装好的spark系统，我们只需要建立一个项目，这个项目可以是java的也可以是scala
然后我们将spark-assembly-1.6.1-hadoop2.6.0.jar这样的jar放入项目的环境里
这个时候我们就可以在本地开发调试spark程序了。
在project Structure中--&gt;libraries中的 --&gt; +号 ，点击添加你放置的jar包的位置
添加依赖包 ：libraries中 添加依赖包： saprk-assembly_2.10-1.0.0-incubating-hadoop2.2.0.jar
&lt;3&gt;scala-sdk
</pre></div>


<h2>3.开发步骤</h2>
<h3>第一步，配置与连接</h3>
<div class="highlight"><pre><span></span>    1.1 maven 配置：配置依赖的包
    1.2 Scala 连接：
        首先创建一个SparkContext对象，该对象有四个参数：Spark master位置、
                                                        应用程序名称，
                                                        Spark安装目录和jar存放位置，
            对于Spark On YARN而言，第一个参数指定为“yarn-standalone”，第二个参数是自定义的字符串，
</pre></div>


<h3>第二步：构建RDD，</h3>
<div class="highlight"><pre><span></span>    第一类是从内存里直接读取数据
    第二类就是从文件系统里读取&lt;注意存储系统类型以及文件格式&gt;
</pre></div>


<h3>第三步：对RDD进行各种运算和操作</h3>
<h3>第四步：输出结果,将程序打包成jar</h3>
<div class="highlight"><pre><span></span>---手动模式
    &lt;1&gt;  File----&gt;Project Structure-----&gt; Artifact   --&gt; +
                                                &lt;playDayCount&gt;                                      
    &lt;2&gt;Build------&gt; BUild Artifact
    在这个文件夹下C:\Items\Spark_Order\out\artifacts\Spark_Order_jar会有Spark_Order.jar的jar包
</pre></div>


<h3>第五步：集群运行Spark---</h3>
<div class="highlight"><pre><span></span>设定系统任务提交 bin/spark-submit脚本执行应用配置开发环境
</pre></div>


<h2>4.出现的问题以及解决方式</h2>
<h3>&lt;问题一&gt; Idea使用Maven创建Scala的类</h3>
<div class="highlight"><pre><span></span>问题一：没有new scala class 的选项
新建中没有scala的类，是什么原因呢，调试了很多方法都没有效果，甚至卸载了重新安装，结果还是无功而返。
虽然已经在在Global libraries中已经设置好了SDK-Scala，但是依然不能使用。尝试了很多方式，依然没有解决问题，最后是偶然的调试，将Scala-SDK添加到library就可以创建Scala的类了。
经过多次尝试，确定最终的解决步骤是
在project Structure中--&gt;Module中的  --&gt;Dependent  --&gt; +号 ，点击添加添加scala-sdk-2.10.6
问题&lt;02&gt;出现问题：at java.net.URLClassLoader$1.run
原因：
解决方案：在通过Project Structure里面的SDKs和Global Libraries设置所需要的jdk和库，结果好了！
</pre></div>


<h3>&lt;问题二&gt;Orcale数据库依赖问题</h3>
<div class="highlight"><pre><span></span>在maven的本地库中添加ojdbc6-11.2.0.4.0.jar，以及ojdbc6-11.2.0.4.0.pom 文件
</pre></div>


<h3>问题三 the winutils binary</h3>
<div class="highlight"><pre><span></span><span class="x"> Failed to locate the winutils binary in the hadoop binary path   java.io.IOException: Could not locate executable null \bin\winutils.exe in the Hadoop binaries.</span>
<span class="x">解决方案：</span>
<span class="x">GitHub上，有人提供了winutils的windows的版本，项目地址是： https://github.com/srccodes/hadoop-common-2.2.0-bin ,直接下载此项目的zip包，下载后是文件名是hadoop-common-2.2.0-bin-master.zip,随便解压到一个目录</span>
<span class="x">环境准备：</span>
<span class="x">C:\My_Files\Config\hadoop-common-2.2.0-bin-master\bin</span>
<span class="x">&lt;1&gt;.下载winutils的windows版本</span>
<span class="x">GitHub上，有人提供了winutils的windows的版本，项目地址是： https://github.com/srccodes/hadoop-common-2.2.0-bin ,直接下载此项目的zip包，下载后是文件名是hadoop-common-2.2.0-bin-master.zip,随便解压到一个目录</span>
<span class="x">&lt;2&gt;.增加用户变量并配置环境变量</span>
<span class="x">增加用户变量HADOOP_HOME，值是下载的zip包解压的目录，然后在</span>
<span class="x">系统变量path里增加</span><span class="p">$</span><span class="nv">HADOOP_HOME</span><span class="x">\bin 即可。 </span>
<span class="x">  &lt;据说这个不影响集群运行---不知道，有待验证&gt;</span>
</pre></div>


<h3>&lt;问题四&gt;Spark版本兼容</h3>
<div class="highlight"><pre><span></span>使用的系统是：using Window 10, Scala 2.10.6, Spark 1.6.0, and Java 1.8
ERROR SparkContext: Error initializing SparkContext.
java.lang.NoSuchMethodException: akka.remote.RemoteActorRefProvider.&lt;init&gt;

原因： Scala 2.10.6 doesn&#39;t support Java 8:
         2.12, will most likely target Java 8 by default.
解决方法：Try installing the Java 7 JDK 
参考：http://stackoverflow.com/questions/39501111/error-sparkcontext-error-initializing-sparkcontext-intellij-and-scala  
 Hadoop  -----  2.7.1.2.4   HDFS MapReduce2 YARN&lt;JDK7
 Spark   -----  1.6.0.2.4   &lt;Scala--2.10.6
 HBase   -----  1.1.2.2.4
</pre></div>


<h3>&lt;问题五&gt;开发中的一些问题</h3>
<div class="highlight"><pre><span></span>&lt;1&gt;数组超标，过界。在有循环的情况下注意
&lt;2&gt;to 和 until 的开闭区间不同，在遇到for循环的情况下，一定要注意循环的终止条件和范围
 Spark的保存模式 
spark的saveAsTextFile方法只能指定文件夹，但是保存到本地的话，会报空指针错误。 
Caused by: java.lang.NullPointerException at java.lang.ProcessBuilder.start(ProcessBuilder.java:1010)
一般而言，saveAsTextFile会按照执行task的多少生成多少个文件，比如part-00一直到part-0n，n自然就是task的个数，亦即是最后的stage的分区数
</pre></div>


<h3>&lt;问题六&gt;操作系统与网络方面的问题</h3>
<div class="highlight"><pre><span></span>Ambari 中一般会设置主机名，而对主机名通常在本机没有设置，所以在调试的过程在运行调试时可能会出现无法找到主机，类似异常信息如下：java.net.UnknownHostException: unknown host: master
master可以是任意名称，例如我的主机名是 unix2，所以报错如:java.net.UnknownHostException: unknown host: unix2     
解决方法:在C:\WINDOWS\system32\drivers\etc\hosts文件中添加如下信息，并在cmd环境下更新DNS：  
192.0.0.1 master  
更新方式是在cmd 下运行 ipconfig /flushdns  
设置好Ambari中主机所对应的IP地址
</pre></div>
    </div><!-- /.entry-content -->

  </article>
</section>
        <section id="extras" class="body">
                <div class="blogroll">
                        <h2>blogroll</h2>
                        <ul>
                            <li><a href="http://getpelican.com/">Pelican</a></li>
                            <li><a href="http://python.org/">Python.org</a></li>
                            <li><a href="https://github.com/ytluck">yt</a></li>
                        </ul>
                </div><!-- /.blogroll -->
                <div class="social">
                        <h2>social</h2>
                        <ul>

                            <li><a href="http://pelican-zh.readthedocs.org/en/latest/zh-cn/settings/">ye</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="http://getpelican.com/">Pelican</a>, which takes great advantage of <a href="http://python.org">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="http://coding.smashingmagazine.com/2009/08/04/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

    <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-76643035-1']);
    _gaq.push(['_trackPageview']);
    (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = 'https://ssl.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
    </script>
</body>
</html>